{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas lesson\n",
    "\n",
    "**Pandas is an open source library that is used to analyze data in Python. It takes in data, like a CSV or SQL database, and creates an object with rows and columns called a data frame. Pandas is typically imported with the alias pd.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Series and Dataframes\n",
    "\n",
    "- Just as the ndarray is the foundation of the NumPy library, the Series is the core object of the pandas library. A pandas Series is very similar to a one-dimensional NumPy array, but it has additional functionality that allows values in the Series to be indexed using labels. A NumPy array does not have the flexibility to do this. This labeling is useful when you are storing pieces of data that have other data associated with them. Say you want to store the ages of students in an online course to eventually figure out the average student age. If stored in a NumPy array, you could only access these ages with the internal ndarray indices 0,1,2.... With a Series object, the indices of values are set to 0,1,2... by default, but you can customize the indices to be other values such as student names so an age can be accessed using a name. Customized indices of a Series are established by sending values into the Series constructor, as you will see below.\n",
    "\n",
    "- A Series holds items of any one data type and can be created by sending in a scalar value, Python list, dictionary, or ndarray as a parameter to the pandas Series constructor. If a dictionary is sent in, the keys may be used as the indices.\n",
    "\n",
    "- Series objects provide more information than NumPy arrays do. Printing a NumPy array of ages does not print the indices or allow us to customize them.\n",
    "\n",
    "- RO: Așa cum ndarray este fundamentul bibliotecii NumPy, Seria este obiectul principal al bibliotecii pandas. O serie pandas este foarte asemănătoare cu o matrice unidimensională NumPy, dar are o funcționalitate suplimentară care permite indexarea valorilor din serie folosind etichete. O matrice NumPy nu are flexibilitatea de a face acest lucru. Această etichetare este utilă atunci când stocați bucăți de date care au asociate alte date. Spuneți că doriți să stocați vârstele studenților într-un curs online pentru a afla în cele din urmă vârsta medie a studenților. Dacă este stocat într-o matrice NumPy, puteți accesa aceste vârste numai cu indicii interni ndarray 0,1,2 .... Cu un obiect Series, indicii valorilor sunt setați la 0,1,2 ... în mod implicit dar puteți personaliza indicii pentru a fi alte valori, cum ar fi numele studenților, astfel încât o vârstă poate fi accesată folosind un nume. Indicii personalizați ai unei serii sunt stabiliți prin trimiterea de valori în constructorul Seriei, așa cum veți vedea mai jos.\n",
    "\n",
    "- O serie conține elemente de orice tip de date și poate fi creată prin trimiterea unei valori scalare, a unei liste Python, a unui dicționar sau a unui ndarray ca parametru către constructorul Seriei pandas. Dacă este trimis un dicționar, tastele pot fi folosite ca indici.\n",
    "\n",
    "\n",
    "**DataFrame**\n",
    "- Another important type of object in the pandas library is the DataFrame. This object is similar in form to a matrix as it consists of rows and columns. Both rows and columns can be indexed with integers or String names. One DataFrame can contain many different types of data types, but within a column, everything has to be the same data type. A column of a DataFrame is essentially a Series. All columns must have the same number of elements (rows).\n",
    "\n",
    "- There are different ways to fill a DataFrame such as with a CSV file, a SQL query, a Python list, or a dictionary. Here we have created a DataFrame using a Python list of lists. Each nested list represents the data in one row of the DataFrame. We use the keyword columns to pass in the list of our custom column names.\n",
    "\n",
    "- RO:Un alt tip important de obiect din biblioteca pandas este DataFrame. Acest obiect are o formă similară cu o matrice, deoarece este format din rânduri și coloane. Ambele rânduri și coloane pot fi indexate cu numere întregi sau nume de șiruri. Un DataFrame poate conține multe tipuri diferite de tipuri de date, dar într-o coloană, totul trebuie să fie același tip de date. O coloană dintr-un DataFrame este în esență o serie. Toate coloanele trebuie să aibă același număr de elemente (rânduri).\n",
    "\n",
    "- Există diferite moduri de a completa un DataFrame, cum ar fi cu un fișier CSV, o interogare SQL, o listă Python sau un dicționar. Aici am creat un DataFrame folosind o listă Python de liste. Fiecare listă imbricată reprezintă datele dintr-un rând al DataFrame. Folosim coloanele de cuvinte cheie pentru a trece în lista numelor noastre de coloane personalizate.\n",
    "\n",
    "**Set the index of DataFrame**\n",
    "- The default row indices are 0,1,2..., but these can be changed. For example, they can be set to be the elements in one of the columns of the DataFrame. To use the names column as indices instead of the default numerical values, we can run the following command on our DataFrame: **dataf.set_index('name')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Loading data from csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'KNN_Dataset.csv' does not exist: b'KNN_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-e62ebcdc1fa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load data intoPandas from a csv(comma separated files)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN_Dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#examine the first 10 rows of you data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'KNN_Dataset.csv' does not exist: b'KNN_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "#load data intoPandas from a csv(comma separated files)\n",
    "df = pd.read_csv(\"KNN_Dataset.csv\")\n",
    "#examine the first 10 rows of you data \n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select specific customized rows**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#select specific rows for someone with age 50 and BMI greater tham 33\n",
    "#you can play with different values \n",
    "df[(df.Age == 50) & (df.BMI >= 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe from a dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame:A DataFrame is an object that stores data as rows and columns, each column has a name which is a string \n",
    "#and each value is a list of column values {\"name\": [\"petru\", \"vera\", \"albert\"]}\n",
    "df1 = pd.DataFrame({\n",
    "    'name': ['John Smith', 'Jane Doe', 'Joe Schmo'],\n",
    "    'address': ['123 Main St.', '456 Maple Ave.', '789 Broadway'],\n",
    "    'age': [34, 28, 51]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataframe by using list of lists**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different way to create dataframe by using list of lists \"[[]]\", each one represents a row of data and each elemnt from list\n",
    "#allocated to one column,using keyword argument  columns to pass a list of coluns names \n",
    "df2 = pd.DataFrame([['John Smith', '123 Main St.', 34], ['Jane Doe', '456 Maple Ave.', 28],['Joe Schmo', '789 Broadway', 51]],\n",
    "    columns=['name', 'address', 'age'])\n",
    "df3 = pd.DataFrame([[\"petru\", 37, \"engineering\"], [\"vera\", 37, \"teacher\"]], columns = [\"name\", \"age\", \"profession\"])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV are datasets that alraedy exsist, first row is the columns heading, all sussequent row contains values  \n",
    "#CSV file each column heading and each variable is separted by comma \n",
    "#column1,column2,column3\n",
    "#value1,value2,value3\n",
    "df4 = pd.DataFrame([['Devil’s Food','chocolate', 'chocolate','chocolate shavings'], \n",
    "                    ['Birthday Cake', 'vanilla', 'vanilla', 'rainbow sprinkles']], \n",
    "                   columns = ['name', 'cake_flavor','frosting_flavor','topping'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print first five rows without header**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#method head() gives the first 5 rows of a dataframe if you want more you can pass head(10)\n",
    "df4 = pd.DataFrame(df)\n",
    "df4.head(10)\n",
    "#method info() give you some statistics information about each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select one column** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'BMI'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-5852d81bb67c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#2. If names of column follow the rules then (do not contains spaces or special characteristics) \"objevct_name.columns_name\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#check up the print after the type method, series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBMI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BMI\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBMI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'BMI'"
     ]
    }
   ],
   "source": [
    "#select one column\n",
    "# 1.selecting the column as you selecting value from a dictionary using a key \n",
    "#2. If names of column follow the rules then (do not contains spaces or special characteristics) \"objevct_name.columns_name\"\n",
    "#check up the print after the type method, series \n",
    "df.BMI\n",
    "df[\"BMI\"]\n",
    "print(type(df.BMI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting more than one column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting more then one column, to select more than one column from dataframe we use a list of the column names \"[[]]\"\n",
    "#check up the print after the type method data frame \n",
    "df[[\"Age\", \"BMI\"]]\n",
    "print(type(df[[\"Age\", \"BMI\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select one row or multiple rows with iloc() command**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#select rows and select multiple rows\n",
    "#data frames are 0 indexed means that starts with 0th row \n",
    "print(df.iloc[1 : 5]) # select the first 4 rows, 5 is excluded\n",
    "print(df.iloc[2:10,0: 4])\n",
    "print()\n",
    "print(type(df.iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select row with logical operators**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Select Rows with Logic I\n",
    "#you can select a subset of a dataframe by using logical statements(=,<,>,!) df[df.MyColumnName == desired_column_value]\n",
    "#for example we want to select a row where the customer's age is 35\n",
    "df[df.Age == 35]\n",
    "#this snippet selects all rows where the customer glucose is not 87\n",
    "df[df.Glucose != 87]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select Rows with Logic II\n",
    "#for example that you want to select rows with customer age under 50 and BMI greater than 35 \"\"| = or\"\n",
    "#daca vrei sa selectezi un interval intre varstele 35 si 50 poti folosi operatorul logic \"or\"\n",
    "df[(df.Age == 50) | (df.Age == 35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Rows with Logic III\n",
    "#command isin() check the value passed in as parameter and returns subset of a dataframe with rows containing those parameter values\n",
    "#suppose we want to select the rows with age 50, 35 and 65\n",
    "df[df.Age.isin([35, 50, 60])]\n",
    "print(type(df[df.Age.isin([35, 50, 65])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select rows with command isin() and reset indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting indices\n",
    "#when we select asubset of a dataframe using logic we end up with nonconsecutive indices \n",
    "#we can fix this using method reset_index(), old indices has been saved under Index column in order to get rid of them use drop = True\n",
    "age_35_50_60 = df[df.Age.isin([35, 50, 65])]\n",
    "df6 = age_35_50_60.reset_index(drop = True, inplace = True)\n",
    "print(df6)\n",
    "#for inplace True returns None, seems that inplace is for overwrite the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding a column I.** \n",
    "\n",
    "One way to add a column is by giving a list of the same length as the existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame([[1, '3 inch screw', 0.5, 0.75],[2, '2 inch nail', 0.10, 0.25],[3, 'hammer', 3.00, 5.50], \n",
    "                   [4, 'screwdriver', 2.50, 3.00]],columns=['Product ID', 'Description', 'Cost to Manufacture', 'Price'])\n",
    "#adding a new column \n",
    "df7[\"quantity\"] = [15, 35, 57, 82]\n",
    "df7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Adding a column II\n",
    "We can also add a new column that is the same for all rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7[\"In_stock\"] = True\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding a column III**\n",
    "\n",
    "We can add a new column by performing a function on the existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7[\"Total\"] = df7.Price * df7.quantity\n",
    "df7[\"Margins\"] = df7.Price - df7[\"Cost to Manufacture\"]\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with columns**\n",
    "\n",
    "Un exemplu de vizualizare cu ajutorul logical operators, am creat un subset iar din acel subset am extras persoanele cu varsta de 50 de ani in cazul de fata am pus BMI dar merge si fara "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KNN_Dataset.csv\")\n",
    "df8 = df[[\"BMI\", \"Age\"]]\n",
    "df11 = df8[df8.Age == 50]\n",
    "df11.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing column operation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.DataFrame([['JOHN SMITH', 'john.smith@gmail.com'],['Jane Doe', 'jdoe@yahoo.com'],['joe schmo', 'joeschmo@hotmail.com']],\n",
    "columns=['Name', 'Email'])\n",
    "df10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Using str() function to add another column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lower function to lowercase the entire column = name_df.name_column.str.lower()\n",
    "# what str does? converts specified value into a string\n",
    "df10[\"Lowercase Name\"] = df10.Name.str.lower()\n",
    "df10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply function = apply a \"function\" along an axis of the data frame, \n",
    "returns series or dataframe. Objects passed to the function are series objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function create the dataframe\n",
    "df1 = pd.DataFrame([[4, 3, 5]] * 3, columns = [\"A\", \"B\", \"C\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify values for entire column and add new column\n",
    "#modify values for entire dataframe \n",
    "df1[\"Sqr\"] = df1.A.apply(np.sqrt)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function for all values returns data frame\n",
    "df1.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-c2617de0abe2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#apply using axis along rows, axis = 0  return series sum of column values with index column name axis = 1 return series sum of row values with index of dataframe indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(type(df2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "#apply using axis along rows, axis = 0  return series sum of column values with index column name axis = 1 return series sum of row values with index of dataframe indexes\n",
    "df2 = df1.apply(np.sum, axis = 1)\n",
    "#print(type(df2))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using lambda with built in function apply**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda function is a way of defening a function in a single line of code ussualy assign it to a variable. Lambda works with all types of variable like strings not only integers lambda x: [outcome if true] if [conditional] else [outcome if false] \n",
    "\n",
    "Applyng lambda to a column, for example we want to create a column with email provider of each email address split() separates a string into a list of strings, you can specify separator where to split the string, maxsplit specifies how many splits to do in our case which halve to keep in to the column we can also operate on multiple columns by not specifying the column name and including axis = 1 the output would be an entire row not a column df[\"new_column_name\"] = df.apply(lambda row: row[\"column_name\"] * quantity if row.second_column == \"Yes\" else row[\"column_name\"]) we can access in both way row.colomn_name or row[\"colomn_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lambda = lambda x: (x + 3) ** 2\n",
    "my_lambda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_str = lambda x: x.lower()\n",
    "lambda_str(\"HELLO\")\n",
    "mylambda = lambda x: x[0] + x[len(x)-1]\n",
    "mylambda(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylambda = lambda x: \"Batterfield No!\" if x >= 13 else \"Wellcome!!!\"\n",
    "print(mylambda(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying lambda to a column\n",
    "df10[\"email_provider\"] = df10.Email.apply(lambda x: x.split('@')[-1])\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lambda to a row\n",
    "df3 = pd.DataFrame({\"names\":['Lauren Durham','Grace Sellers','Shirley Rasmussen','Brian Rojas','Samantha Mosley','Louis Guzman','Denise Mcclure','James Raymond'], \"hourly_wage\" : [19, 18, 14, 17, 19, 18, 13, 17], \"hours_worked\" : [43,30,47,38,39,40,42,45]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column with operation between two columns \n",
    "total_earned = lambda row: row[\"hourly_wage\"] * (40 + (row[\"hours_worked\"] - 40) * 1.5) if row[\"hours_worked\"]  > 40 else row[\"hours_worked\"] * row[\"hourly_wage\"]\n",
    "df3[\"total_earned\"] = df3.apply(total_earned, axis = 1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming columns name**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#renaming columns but for all at once, this command modify existing dataframe\n",
    "df3.columns = [\"Names\", \"Hourlywage\", \"Hours_worked\", \"Total_earned\"]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second way to modify the header with method rename(),aceasta metod creeaza un nou data frame  keyword inplace save unchanged the original data frame\n",
    "df6 = pd.DataFrame({'name': ['John', 'Jane', 'Sue', 'Fred'],'age': [23, 29, 21, 18]})\n",
    "\n",
    "df6.rename(columns = {\"name\" : \"Name\", \"age\" : \"Age\"}, inplace = True)\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recapitulare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recapitulare\n",
    "df4 = df3[df3.names == \"Grace Sellers\"]\n",
    "df4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "df5 = df3[(df3.Hourlywage >= 18) & (df3[\"Hours_worked\"] == 30)]\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second way to modify the header with method rename(),aceasta metod creeaza un nou data frame  keyword inplace save unchanged the original data frame\n",
    "df6 = pd.DataFrame({'name': ['John', 'Jane', 'Sue', 'Fred'],'age': [23, 29, 21, 18]})\n",
    "\n",
    "df6.rename(columns = {\"name\" : \"Name\", \"age\" : \"Age\"}, inplace = True)\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#metoda de calcul intre  doua coloane\n",
    "df3[\"starter\"] = df3[\"Hourlywage\"] - df3[\"Hours_worked\"]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Column Statistics**\n",
    "\n",
    "The general syntax of these calculations is: df.coulumn_name.command()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#calculate the median value for one column\n",
    "df3.Hourlywage.median()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#you want to know unique value = how many different groups with same value are in your column, the output is an integer.\n",
    "df3[\"Hours_worked\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max value from a column\n",
    "df3.starter.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.mean()# mean value of the column\n",
    "df.Age.median()\n",
    "df.Age.std()#standard deviation \n",
    "df.Age.count()#number of values in column \n",
    "df.Age.min()#minimum value in column \n",
    "df.Age.nunique()#number of unique values in colomn \n",
    "df.Age.unique()#list of unique values in column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Aggregate Fuctions I**\n",
    "\n",
    "Following command syntax : df.groupby(\"column1\").column2.measurement()\n",
    "\n",
    "column1 is the column that we want to group by \n",
    "\n",
    "column2 is the column the we want to perform a measurement \n",
    "\n",
    "measurement is the measurement function want to apply \n",
    "\n",
    "returns a new series in order to return dataframe add method reset_index() on top of measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following command helps you to find the average age for each pregancies across all assigments \n",
    "df = pd.read_csv(\"KNN_Dataset.csv\")\n",
    "age = df.groupby('Pregnancies').Age.mean().reset_index()\n",
    "age\n",
    "print(type(age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Aggregate Functions II**\n",
    "\n",
    "rename the column name by using replace(columns = {value : to replace})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloodpressure = df.groupby(\"BloodPressure\").Age.count().reset_index()\n",
    "bloodpressure[\"BloodPressure\"].max()\n",
    "bloodpressure = bloodpressure.rename(columns = {\"Age\" : \"Counts\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Aggregate Functions III**\n",
    "\n",
    "for more complicated operation is handly using apply() method and lambda functions\n",
    "\n",
    "exampe: you want to **calculate percentile** of Glucose with respect of Age:  new_object = df.groupby(\"column1\").column2.apply(lambda x: np.percentile(x, 75)).reset_index()\n",
    "\n",
    "Return dataframe with one column Age and second column Glucose with value of percentege feed in to the percentile function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = df.groupby(\"Age\").Glucose.apply(lambda x: np.percentile(x, 75)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numpy percentile()**\n",
    "\n",
    "Example: if you have ana array of numeric values in ascending order, applying method percentile(array_name, percentege), will return sinngle output according to percentege paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[10, 7, 4], [3, 2, 1]])\n",
    "np.percentile(a, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 4.5, 2.5])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(a, 50, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 2.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(a, 50, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Aggregate Functions IV**\n",
    "\n",
    "grouping by more than one column, we can do this by adding a list of columns name \n",
    "\n",
    "Acest exemplu nu este tocmai relevant pentru acest subiect, functioneaza atunci cand ai o coloana cu week_date si grupezi dupa nume si data, masori valoarea maxima a vanzarilor facute de catre un magazin pentru fiecare zi, considerand ca ai mai multe magazine si vrei sa vezi care face vanzarea cea mai mare "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "twocolumns = df.groupby([\"BloodPressure\", \"BMI\"]).Glucose.count().reset_index()\n",
    "twocolumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot Tables**\n",
    "pandas.dataframe.pivot(self, index=None, columns=None, values=None) command reorganize a table( te ajuta sa vezi si sa intelegi mai bine datele), is usable for subsets and after groupby() method\n",
    "\n",
    "index = string sau object se refera la numele coloanei, va indexa noul tabel cu valorile din coloana respectiva\n",
    "\n",
    "columns = string sau object se refera la numele unei coloane, va crea un nou header de col_names cu val. din coloana respectiva\n",
    "\n",
    "values = str or object, coloana folosit pentru a popula interiorul tabelului, daca nu este folosit va umple cu coloanele nefolosite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
    "'two'],'bar': ['A', 'B', 'C', 'A', 'B', 'C'],'baz': [1, 2, 3, 4, 5, 6],'zoo': ['x', 'y', 'z', 'q', 'w', 't']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>two</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bar  foo  A  B  C\n",
       "0    one  1  2  3\n",
       "1    two  4  5  6"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of using pivot()\n",
    "table = df11.pivot( index = \"foo\", columns = \"bar\", values = \"baz\")\n",
    "table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th colspan=\"3\" halign=\"left\">baz</th>\n",
       "      <th colspan=\"3\" halign=\"left\">zoo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>two</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>q</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     foo baz       zoo      \n",
       "bar        A  B  C   A  B  C\n",
       "0    one   1  2  3   x  y  z\n",
       "1    two   4  5  6   q  w  t"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second example of using pivot\n",
    "table1 = df11.pivot(index = \"foo\", columns = \"bar\", values = [\"baz\", \"zoo\"])\n",
    "table1.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recapitulare**\n",
    "\n",
    "The \"~\" is a NOT operator and isna() test whether or not the value of column is null, Obs!--> codacademy use isnull() and does the same as isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True],\n",
       "       [ True,  True, False]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "~pd.isna(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'KNN_Dataset.csv' does not exist: b'KNN_Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-b1aa9d50bc73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN_Dataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'KNN_Dataset.csv' does not exist: b'KNN_Dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"KNN_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group1 = df.groupby([\"Pregnancies\"]).BloodPressure.count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error = \"lambda cannot contain assignment\" inseamna ca x nu poate sa fie egal cu expresia sau sintaxa \"x = df.Insulin.mean()\"(gresit), daca punem \"==\" returns False or True , fara egal sau assign return valoarea medie a coloanei**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round the value but new object need to be created \n",
    "df[\"Insulin\"] = df.Insulin.apply(lambda x: df.Insulin.mean() if x == 0 else x)\n",
    "df1 = np.round(df, decimals = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#same shit \n",
    "df.Insulin.apply(np.ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction: Multiple DataFrames**\n",
    "\n",
    "**Merge method**\n",
    "\n",
    "A Venn diagram of the intersection of two sets. The RED area is the intersection. This is what we get from an INNER MERGE.\n",
    "\n",
    "In Pandas the .merge() function uses an inner merge by default. An inner merge can be thought of as the intersection between two (or more) DataFrames. This is similar to a Venn diagram. In other words, an inner merge only returns rows both tables have in common. Any rows in one DataFrame that are not in the other, will not be in the result.\n",
    "\n",
    "The .merge method looks for columns that are common between two DataFrames and then looks for rows where those column’s values are the same. It then combines the matching rows into a single row in a new table.\n",
    "Pe scurt daca avem doua tabele cu coloane asemanatoare, merge method va trece prin coloane si randuri si va crea un nou df cu coloanele comune din cele doua df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
    "                    'value': [1, 2, 3, 5]})\n",
    "df13 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
    "                  'value': [5, 6, 7, 8]})\n",
    "print(df12)\n",
    "print(df13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df12, df13)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df12, df13, left_on = \"lkey\", right_on = \"rkey\", suffixes = (\"_left\", \"_right\"), how = \"right\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New method to merge data frame**\n",
    "\n",
    "Cam merge also 3 or more frames Example: big_df = orders.merge(customers).merge(products).merge(purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge = df12.merge(df13)\n",
    "new_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not all the time same name of column could have different content**\n",
    "\n",
    "Example: Both df have one column named id but row content is differnt, this fact makes merging difficult. One option is to rename column: pd.merge(orders, customers.rename(columns={'id': 'customer_id'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge on Specific Columns II**\n",
    "\n",
    "Another option to to chnage the column name is by using keywords left_on, and right_on to specify which columns to perform the merge on.\n",
    "Example:  In the example below, the “left” table is the one that comes first (orders), and the “right” table is the one that comes second (customers). This syntax says that we should match the customer_id from orders to the id in customers.\n",
    "\n",
    "pd.merge(orders, customers, left_on='customer_id', right_on='id'). \n",
    "\n",
    "If we use this syntax, we’ll end up with two columns called id, one from the first table and one from the second. Pandas won’t let you have two columns with the same name, so it will change them to id_x and id_y.\n",
    "\n",
    "The new column names id_x and id_y aren’t very helpful for us when we read the table. We can help make them more useful by using the keyword suffixes. We can provide a list of suffixes to use instead of “_x” and “_y”.\n",
    "\n",
    "pd.merge(orders,customers,left_on='customer_id',right_on='id',suffixes=['_order', '_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outer Merge**\n",
    "\n",
    "we saw that when we merge two DataFrames whose rows don’t match perfectly, we lose the unmatched rows. This type of merge (where we only include matching rows) is called an inner merge. There are other types of merges that we can use when we want to keep information from the unmatched rows.\n",
    "\n",
    "Suppose that two companies, Company A and Company B have just merged. They each have a list of customers, but they keep slightly different data. Company A has each customer’s name and email. Company B has each customer’s name and phone number. They have some customers in common, but some are different.\n",
    "\n",
    "If we wanted to combine the data from both companies without losing the customers who are missing from one of the tables, we could use an Outer Join. An Outer Join would include all rows from both tables, even if they don’t match. Any missing values are filled in with None or nan (which stands for “Not a Number”).\n",
    "\n",
    "Example of syntax: pd.merge(company_a, company_b, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_outer = pd.merge(df12, df13, how = \"outer\")\n",
    "merged_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of SQL  = Structured Query Language**\n",
    "\n",
    "A table is a collection of related data held in a table format within a database,  a table is a set of data elements (values) using a model of vertical columns (identifiable by name) and horizontal rows, the cell being the unit where a row and column intersect.\n",
    "\n",
    "What is SQL? SQL (Structured Query Language) is a programming language used to communicate with data stored in a relational database management system. SQL syntax is similar to the English language, which makes it relatively easy to write, read, and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Left Merge Right Merge**\n",
    "\n",
    "A Left Merge includes all rows from the first (left) table, but only rows from the second (right) table that match the first table.\n",
    "\n",
    "Right merge is the exact opposite of left merge. Here, the merged table will include all rows from the second (right) table, but only rows from the first (left) table that match the second table.\n",
    "\n",
    "If a key combination does not appear in either the left or right tables, the values in the joined table will be NA. The items with null in value are carried by df12, but not df13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_left = pd.merge(df12, df13, how = \"left\")\n",
    "merged_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_right = pd.merge(df12, df13, how = \"right\")\n",
    "merged_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate DataFrames**\n",
    "\n",
    "Sometimes, a dataset is broken into multiple tables. For instance, data is often split into multiple CSV files so that each download is smaller.\n",
    "\n",
    "When we need to reconstruct a single DataFrame from multiple smaller DataFrames, we can use the method pd.concat([df1, df2, df2, ...]). This method only works if all of the columns are the same in all of the DataFrames.\n",
    "\n",
    "The concat() function (in the main pandas namespace) does all of the heavy lifting of performing concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes. Note that I say “if any” because there is only a single possible axis of concatenation for Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],'B': ['B0', 'B1', 'B2', 'B3'],'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']},index=[0, 1, 2, 3]) #indexing the dataframe \n",
    "df15 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],'B': ['B4', 'B5', 'B6', 'B7'],'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                     'D': ['D4', 'D5', 'D6', 'D7']},index=[4, 5, 6, 7])#indexing the dataframe\n",
    "df16 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],'D': ['D2', 'D3', 'D6', 'D7'],'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])\n",
    "df16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df14, df15]\n",
    "pd.concat(frames).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set axis 1, and take the intersection join = \"inner\", inner is for intersection \n",
    "pd.concat([df14, df16], axis = 1, join = \"inner\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are acelasi outup ca si pd.concat() method\n",
    "pd.merge(df14, df15, how = \"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas isnull() notnull()**\n",
    "\n",
    "While making a Data Frame from a csv file, many blank columns are imported as null value into the Data Frame which later creates problems while operating that data frame. Pandas isnull() and notnull() methods are used to check and manage NULL values in a data frame\n",
    "\n",
    "Return Type: Dataframe of Boolean values which are True for NaN values\n",
    "\n",
    "notnull() return False for NaN and isnull() return True for NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([[2, np.nan, 3], [6, 7, np.nan]])\n",
    "pd.isnull(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas fillna()**\n",
    "\n",
    "Replace null values into the dataframe, manage and let the user replace NaN values with some value of their own \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df17 = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "                   [3, 4, np.nan, 1],\n",
    "                   [np.nan, np.nan, np.nan, 5],\n",
    "                   [np.nan, 3, np.nan, 4]],\n",
    "                  columns=list('ABCD'))\n",
    "df17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can propagate non-null values forward or backward\n",
    "values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "df17.fillna(value = values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN elements with 0\n",
    "df17.fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only replace the NaN element\n",
    "df17.fillna(value=values, limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas apply() function**\n",
    "\n",
    "The Pandas apply() function can be used to apply a function on every value in a column or row of a DataFrame, and transform that column or row to the resulting values.\n",
    "\n",
    "By default, it will apply a function to all values of a column. To perform it on a row instead, you can specify the argument axis=1 in the apply() function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df18 = pd.DataFrame({\"names\":['Lauren Durham','Grace Sellers','Shirley Rasmussen','Brian Rojas','Samantha Mosley','Louis Guzman','Denise Mcclure','James Raymond'], \"hourly_wage\" : [19, 18, 14, 17, 19, 18, 13, 17], \"hours_worked\" : [43,30,47,38,39,40,42,45]})\n",
    "df18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this functions doubles the input value\n",
    "def double(x):\n",
    "    return x * 2\n",
    "#apply this function to double each value ina specified columns\n",
    "#lambda function can also be supplied to apply\n",
    "mylambad = lambda x: x - 3\n",
    "df18[\"hours_doubled\"] = df18['hours_worked'].apply(double)\n",
    "df18[\"without_bonus\"] = df18[\"hourly_wage\"].apply(double)\n",
    "df18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas’ Groupby**\n",
    "\n",
    "In a pandas DataFrame, aggregate statistic functions can be applied across multiple rows by using a groupby function. In the example, the code takes all of the elements that are the same in Name and groups them, replacing the values in Grade with their mean. Instead of mean() any aggregate statistics function, like median() or max(), can be used. Note that to use the groupby() function, at least two columns must be supplied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficient Data Storage with Multiple Tables**\n",
    "\n",
    "For efficient data storage, related information is often spread across multiple tables of a database.\n",
    "\n",
    "Consider an e-commerce business that tracks the products that have been ordered from its website. Business data for the company could be split into three tables:\n",
    "\n",
    "**orders** would contain the information necessary to describe an order: order_id, customer_id, product_id, quantity, and timestamp\n",
    "\n",
    "**products** would contain the information to describe each product: product_id, product_description and product_price\n",
    "\n",
    "**customers** would contain the information for each customer: customer_id, customer_name, customer_address, and customer_phone_number\n",
    "\n",
    "This table structure prevents the storage of redundant information, given that each customer’s and product’s information is only stored once, rather than each time a customer places an order for another item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df19 = pd.DataFrame({\n",
    "  'model': ['Model S', 'Audi A4'],\n",
    "  'price': [320550, 480250], \n",
    "})\n",
    "df19[\"company\"] = [\"Tesla\", \"Audi\"]\n",
    "df19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Pandas dataframe into a list**\n",
    "\n",
    "df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = {'Product': ['Tablet','iPhone','Laptop','Monitor'],\n",
    "            'Price': [250,800,1200,300]\n",
    "            }\n",
    "df = pd.DataFrame(products, columns= ['Product', 'Price'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one case\n",
    "products_list = df.values.tolist()\n",
    "print (products_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second case\n",
    "to_list = df.Product.tolist()\n",
    "print(to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Format**\n",
    "\n",
    "**AttributeError: 'str' object has no attribute 'datetime'**\n",
    "\n",
    "Columns with dates are string format in DataFrame.\n",
    "\n",
    "This error means that your data type is string format and needs to be converted in Timestamp in order to split up date to : year, month, day, minutes, seconds and create a new column see example below\n",
    "\n",
    "**'Timestamp' object has no attribute 'split'**\n",
    "\n",
    "Guess what, the format is the other way arround and if you would like to split date and filter just one element, you cannot use split() because this works with string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case three \n",
    "split_date = lambda row: row.split('/') [0]\n",
    "birth['month'] = birth['date_of_birth'].apply(split_date)\n",
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth = pd.DataFrame({\n",
    "    'name': ['alice','bob','charlie'],\n",
    "    'date_of_birth': ['10/25/2005','10/29/2002','01/01/2001']})\n",
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case one \n",
    "birth['date_of_birth'] = pd.to_datetime(birth['date_of_birth'])\n",
    "birth['month'] = birth['date_of_birth'].apply(lambda x: x.strftime('%m'))\n",
    "birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case two \n",
    "birth['date_of_birth'] = pd.to_datetime(birth['date_of_birth'])\n",
    "birth['month'] = birth['date_of_birth'].dt.month\n",
    "birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine whether someone is old or young and then add that classification to a new column**\n",
    "- create a new column where user is classified by the age, people under 50 years age is considered young and the rest elderly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df20 = pd.read_csv(\"KNN_Dataset.csv\")\n",
    "df20.loc[df20.Age < 50, 'Aspect']= 'young'\n",
    "df20.loc[df20.Age >= 50, 'Aspect']= 'elderly'\n",
    "df20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing Data** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>-2.385919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>-0.603053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>1.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>1.704744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>1.306527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>-0.058613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>2.129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>0.056776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>-1.254301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>-1.766781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>-0.350348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>-1.009972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2020-01-01 -0.572661 -0.050464  0.762483 -2.385919\n",
       "2020-01-02  2.919911  1.396706  0.094701 -0.603053\n",
       "2020-01-03 -0.209194  1.803362  1.109902  1.002059\n",
       "2020-01-04 -1.411792  1.254757  0.136934  1.704744\n",
       "2020-01-05 -0.978627 -1.610419  0.192010  1.306527\n",
       "2020-01-06  0.031807 -0.324628 -1.038920 -0.058613\n",
       "2020-01-07  0.433070  1.450830 -1.397582  2.129155\n",
       "2020-01-08  0.566084 -0.338410  0.421704  0.056776\n",
       "2020-01-09  0.656360 -1.348109 -1.018954 -1.254301\n",
       "2020-01-10  0.129024 -1.443690 -1.122057 -1.766781\n",
       "2020-01-11 -0.863389  0.420119 -1.633323 -0.350348\n",
       "2020-01-12  1.111048  0.510482  0.483480 -1.009972"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame by passing a NumPy array, with a datetime index and labeled columns:\n",
    "dates = pd.date_range('20200101', periods=12)\n",
    "date_df = pd.DataFrame(np.random.randn(12, 4), index = dates, columns = list('ABCD'))\n",
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C    float64\n",
       "D    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display  data type of the dataframe \n",
    "date_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>-1.766781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>-0.350348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>-1.009972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2020-01-10  0.129024 -1.443690 -1.122057 -1.766781\n",
       "2020-01-11 -0.863389  0.420119 -1.633323 -0.350348\n",
       "2020-01-12  1.111048  0.510482  0.483480 -1.009972"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to view last rows\n",
    "date_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n",
       "               '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08',\n",
       "               '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the index \n",
    "date_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the columns\n",
    "date_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame** has columns with different data types, which comes down to a fundamental difference between pandas and NumPy: **NumPy** arrays have one dtype for the entire array, while pandas DataFrames have one dtype per column. **DataFrame.to_numpy()**, pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. This may end up being object, which requires casting every value to a Python object.\n",
    "\n",
    "**DataFrame.to_numpy() does not include the index or column labels in the output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57266114, -0.05046388,  0.76248312, -2.38591853],\n",
       "       [ 2.91991147,  1.39670588,  0.09470105, -0.60305284],\n",
       "       [-0.20919378,  1.80336227,  1.10990178,  1.00205887],\n",
       "       [-1.4117922 ,  1.25475709,  0.13693392,  1.7047435 ],\n",
       "       [-0.97862677, -1.61041882,  0.19200995,  1.3065272 ],\n",
       "       [ 0.03180747, -0.32462799, -1.03892008, -0.05861349],\n",
       "       [ 0.43307008,  1.45083033, -1.39758218,  2.1291553 ],\n",
       "       [ 0.56608375, -0.33841027,  0.42170407,  0.05677612],\n",
       "       [ 0.6563597 , -1.34810891, -1.01895381, -1.25430148],\n",
       "       [ 0.12902435, -1.44369044, -1.12205694, -1.76678147],\n",
       "       [-0.8633887 ,  0.42011885, -1.63332319, -0.35034809],\n",
       "       [ 1.11104761,  0.51048245,  0.48348026, -1.00997214]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.150970</td>\n",
       "      <td>0.143378</td>\n",
       "      <td>-0.250802</td>\n",
       "      <td>-0.102477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.148568</td>\n",
       "      <td>1.198111</td>\n",
       "      <td>0.930896</td>\n",
       "      <td>1.411804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>-2.385919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.645343</td>\n",
       "      <td>-0.590835</td>\n",
       "      <td>-1.059704</td>\n",
       "      <td>-1.071054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.080416</td>\n",
       "      <td>0.184827</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>-0.204481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.588653</td>\n",
       "      <td>1.290244</td>\n",
       "      <td>0.437148</td>\n",
       "      <td>1.078176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>2.129155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A          B          C          D\n",
       "count  12.000000  12.000000  12.000000  12.000000\n",
       "mean    0.150970   0.143378  -0.250802  -0.102477\n",
       "std     1.148568   1.198111   0.930896   1.411804\n",
       "min    -1.411792  -1.610419  -1.633323  -2.385919\n",
       "25%    -0.645343  -0.590835  -1.059704  -1.071054\n",
       "50%     0.080416   0.184827   0.115817  -0.204481\n",
       "75%     0.588653   1.290244   0.437148   1.078176\n",
       "max     2.919911   1.803362   1.109902   2.129155"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.describe() shows a quick statistic of your data \n",
    "date_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2020-01-01</th>\n",
       "      <th>2020-01-02</th>\n",
       "      <th>2020-01-03</th>\n",
       "      <th>2020-01-04</th>\n",
       "      <th>2020-01-05</th>\n",
       "      <th>2020-01-06</th>\n",
       "      <th>2020-01-07</th>\n",
       "      <th>2020-01-08</th>\n",
       "      <th>2020-01-09</th>\n",
       "      <th>2020-01-10</th>\n",
       "      <th>2020-01-11</th>\n",
       "      <th>2020-01-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>1.111048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>0.510482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>0.483480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D</td>\n",
       "      <td>-2.385919</td>\n",
       "      <td>-0.603053</td>\n",
       "      <td>1.002059</td>\n",
       "      <td>1.704744</td>\n",
       "      <td>1.306527</td>\n",
       "      <td>-0.058613</td>\n",
       "      <td>2.129155</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>-1.254301</td>\n",
       "      <td>-1.766781</td>\n",
       "      <td>-0.350348</td>\n",
       "      <td>-1.009972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2020-01-01  2020-01-02  2020-01-03  2020-01-04  2020-01-05  2020-01-06  \\\n",
       "A   -0.572661    2.919911   -0.209194   -1.411792   -0.978627    0.031807   \n",
       "B   -0.050464    1.396706    1.803362    1.254757   -1.610419   -0.324628   \n",
       "C    0.762483    0.094701    1.109902    0.136934    0.192010   -1.038920   \n",
       "D   -2.385919   -0.603053    1.002059    1.704744    1.306527   -0.058613   \n",
       "\n",
       "   2020-01-07  2020-01-08  2020-01-09  2020-01-10  2020-01-11  2020-01-12  \n",
       "A    0.433070    0.566084    0.656360    0.129024   -0.863389    1.111048  \n",
       "B    1.450830   -0.338410   -1.348109   -1.443690    0.420119    0.510482  \n",
       "C   -1.397582    0.421704   -1.018954   -1.122057   -1.633323    0.483480  \n",
       "D    2.129155    0.056776   -1.254301   -1.766781   -0.350348   -1.009972  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transposing your data\n",
    "date_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-2.385919</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>-0.572661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>-0.603053</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>2.919911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>1.002059</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>-0.209194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>1.704744</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>-1.411792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1.306527</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>-0.978627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-0.058613</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>0.031807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2.129155</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>0.433070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.566084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>-1.254301</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>0.656360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>-1.766781</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>0.129024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.350348</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-0.863389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>-1.009972</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>1.111048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   D         C         B         A\n",
       "2020-01-01 -2.385919  0.762483 -0.050464 -0.572661\n",
       "2020-01-02 -0.603053  0.094701  1.396706  2.919911\n",
       "2020-01-03  1.002059  1.109902  1.803362 -0.209194\n",
       "2020-01-04  1.704744  0.136934  1.254757 -1.411792\n",
       "2020-01-05  1.306527  0.192010 -1.610419 -0.978627\n",
       "2020-01-06 -0.058613 -1.038920 -0.324628  0.031807\n",
       "2020-01-07  2.129155 -1.397582  1.450830  0.433070\n",
       "2020-01-08  0.056776  0.421704 -0.338410  0.566084\n",
       "2020-01-09 -1.254301 -1.018954 -1.348109  0.656360\n",
       "2020-01-10 -1.766781 -1.122057 -1.443690  0.129024\n",
       "2020-01-11 -0.350348 -1.633323  0.420119 -0.863389\n",
       "2020-01-12 -1.009972  0.483480  0.510482  1.111048"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting by an axis modifying only the indexes and header\n",
    "date_df.sort_index(axis = 1, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    E\n",
       "2020-01-02  2.919911  1.396706  0.094701  5  0.0\n",
       "2020-01-12  1.111048  0.510482  0.483480  5  0.0\n",
       "2020-01-09  0.656360 -1.348109 -1.018954  5  NaN\n",
       "2020-01-08  0.566084 -0.338410  0.421704  5  NaN\n",
       "2020-01-07  0.433070  1.450830 -1.397582  5  NaN\n",
       "2020-01-10  0.129024 -1.443690 -1.122057  5  NaN\n",
       "2020-01-06  0.031807 -0.324628 -1.038920  5  NaN\n",
       "2020-01-03 -0.209194  1.803362  1.109902  5  NaN\n",
       "2020-01-01 -0.572661 -0.050464  0.762483  5  NaN\n",
       "2020-01-11 -0.863389  0.420119 -1.633323  5  NaN\n",
       "2020-01-05 -0.978627 -1.610419  0.192010  5  NaN\n",
       "2020-01-04 -1.411792  1.254757  0.136934  5  NaN"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sortin by values \n",
    "date_df.sort_values(by = 'A', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection by label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2020-01-02  2.919911  1.396706\n",
       "2020-01-03 -0.209194  1.803362\n",
       "2020-01-04 -1.411792  1.254757"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " date_df.loc['20200102':'20200104', ['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection by position**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>5</td>\n",
       "      <td>1.396706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.610419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>5</td>\n",
       "      <td>0.510482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A  D         B\n",
       "2020-01-02  2.919911  5  1.396706\n",
       "2020-01-05 -0.978627  5 -1.610419\n",
       "2020-01-12  1.111048  5  0.510482"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.iloc[[1, 4, 11], [0, 3, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>5</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>5</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>5</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>5</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D     E\n",
       "2020-01-01 -0.572661 -0.050464  0.762483  5   one\n",
       "2020-01-02  2.919911  1.396706  0.094701  5   one\n",
       "2020-01-03 -0.209194  1.803362  1.109902  5   two\n",
       "2020-01-08  0.566084 -0.338410  0.421704  5   two\n",
       "2020-01-09  0.656360 -1.348109 -1.018954  5  nine\n",
       "2020-01-11 -0.863389  0.420119 -1.633323  5  nine"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the isin() method for filtering.\n",
    "new_df = date_df.copy(deep = False)\n",
    "new_df['E'] =  ['one', 'one', 'two', 'three', 'four', 'three', 'eight', 'two', 'nine', 'seven', 'nine', 'ten']\n",
    "new_df[new_df['E'].isin(['nine', 'two', 'one'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to use shallow copy?**\n",
    "\n",
    "- When you want to share updates between DataFrames entirely or partially, if you create a new column on the shallow copy, it will not reflect in the original DataFrame. The update is only shared if you work with data that is available in the original DataFrame. Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  4  4\n",
      "1  5  5\n",
      "2  6  6\n",
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "'A': [1, 2, 3],\n",
    "'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "deep_copy = df.copy(deep=True)\n",
    "\n",
    "deep_copy['A'] = [4, 5, 6]\n",
    "\n",
    "print(deep_copy)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Copy [DataFrame.copy(deep=True)]**\n",
    "- When we create a copy of the DataFrame using deep copy (DataFrame.copy(deep=True)), we are creating a copy that has its own data and index. So any modifications to the new DataFrame will not modify the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  9  4\n",
      "1  9  5\n",
      "2  9  6\n",
      "   A  B\n",
      "0  9  4\n",
      "1  9  5\n",
      "2  9  6\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "'A': [1, 2, 3],\n",
    "'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "shallow_copy = df.copy(deep=False)\n",
    "\n",
    "shallow_copy['A'] = [9, 9, 9]\n",
    "\n",
    "print(shallow_copy)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    E\n",
       "2020-01-01 -0.572661 -0.050464  0.762483  5  NaN\n",
       "2020-01-02  2.919911  1.396706  0.094701  5  0.0\n",
       "2020-01-03 -0.209194  1.803362  1.109902  5  NaN\n",
       "2020-01-04 -1.411792  1.254757  0.136934  5  NaN\n",
       "2020-01-05 -0.978627 -1.610419  0.192010  5  NaN"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting values by label \n",
    "date_df.at[dates[1], 'E'] = 0\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    E\n",
       "2020-01-01 -0.572661 -0.050464  0.762483  5  NaN\n",
       "2020-01-02  2.919911  1.396706  0.094701  5  0.0\n",
       "2020-01-03 -0.209194  1.803362  1.109902  5  NaN\n",
       "2020-01-04 -1.411792  1.254757  0.136934  5  NaN\n",
       "2020-01-05 -0.978627 -1.610419  0.192010  5  NaN\n",
       "2020-01-06  0.031807 -0.324628 -1.038920  5  NaN\n",
       "2020-01-07  0.433070  1.450830 -1.397582  5  NaN\n",
       "2020-01-08  0.566084 -0.338410  0.421704  5  NaN\n",
       "2020-01-09  0.656360 -1.348109 -1.018954  5  NaN\n",
       "2020-01-10  0.129024 -1.443690 -1.122057  5  NaN\n",
       "2020-01-11 -0.863389  0.420119 -1.633323  5  NaN\n",
       "2020-01-12  1.111048  0.510482  0.483480  5  0.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.loc[:, 'D'] = np.array([5] * len(date_df))\n",
    "date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data** \n",
    "- To drop any rows that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    E\n",
       "2020-01-02  2.919911  1.396706  0.094701  5  0.0\n",
       "2020-01-12  1.111048  0.510482  0.483480  5  0.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any row with missing data \n",
    "date_df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>-0.572661</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2.919911</td>\n",
       "      <td>1.396706</td>\n",
       "      <td>0.094701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>1.803362</td>\n",
       "      <td>1.109902</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>-1.411792</td>\n",
       "      <td>1.254757</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>-1.610419</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>-0.324628</td>\n",
       "      <td>-1.038920</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0.433070</td>\n",
       "      <td>1.450830</td>\n",
       "      <td>-1.397582</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.566084</td>\n",
       "      <td>-0.338410</td>\n",
       "      <td>0.421704</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>-1.348109</td>\n",
       "      <td>-1.018954</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>-1.443690</td>\n",
       "      <td>-1.122057</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>-0.863389</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>-1.633323</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>1.111048</td>\n",
       "      <td>0.510482</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    E\n",
       "2020-01-01 -0.572661 -0.050464  0.762483  5  5.0\n",
       "2020-01-02  2.919911  1.396706  0.094701  5  0.0\n",
       "2020-01-03 -0.209194  1.803362  1.109902  5  5.0\n",
       "2020-01-04 -1.411792  1.254757  0.136934  5  5.0\n",
       "2020-01-05 -0.978627 -1.610419  0.192010  5  5.0\n",
       "2020-01-06  0.031807 -0.324628 -1.038920  5  5.0\n",
       "2020-01-07  0.433070  1.450830 -1.397582  5  5.0\n",
       "2020-01-08  0.566084 -0.338410  0.421704  5  5.0\n",
       "2020-01-09  0.656360 -1.348109 -1.018954  5  5.0\n",
       "2020-01-10  0.129024 -1.443690 -1.122057  5  5.0\n",
       "2020-01-11 -0.863389  0.420119 -1.633323  5  5.0\n",
       "2020-01-12  1.111048  0.510482  0.483480  5  0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling missing data \n",
    "date_df.fillna(value = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A      B      C      D      E\n",
       "2020-01-01  False  False  False  False   True\n",
       "2020-01-02  False  False  False  False  False\n",
       "2020-01-03  False  False  False  False   True\n",
       "2020-01-04  False  False  False  False   True\n",
       "2020-01-05  False  False  False  False   True\n",
       "2020-01-06  False  False  False  False   True\n",
       "2020-01-07  False  False  False  False   True\n",
       "2020-01-08  False  False  False  False   True\n",
       "2020-01-09  False  False  False  False   True\n",
       "2020-01-10  False  False  False  False   True\n",
       "2020-01-11  False  False  False  False   True\n",
       "2020-01-12  False  False  False  False  False"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the boolean mask where values are nan.\n",
    "pd.isna(date_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a\n",
       "1       b\n",
       "2       c\n",
       "3    aaba\n",
       "4    baca\n",
       "5     NaN\n",
       "6    caba\n",
       "7     dog\n",
       "8     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
